/*
 * TunePad
 *
 * Michael S. Horn
 * Northwestern University
 * michael-horn@northwestern.edu
 *
 * This project was funded by the National Science Foundation (grant DRL-1612619).
 * Any opinions, findings and conclusions or recommendations expressed in this
 * material are those of the author(s) and do not necessarily reflect the views
 * of the National Science Foundation (NSF).
 */
import { TraceEvent } from "../core/trace";
import { SynthChain } from "./chain";
import { clamp } from "../core";

interface EffectParams {
    start : number;
    beats : number;
    values : Array<(number | Array<number>)>;
}

const DefaultEffectParams = {
    start: 0,
    beats: 0,
    values: [ ]
};

/// Audio effects can be added to a synthesizer's fx "stack".
/// Some effects get layered together in the audio chain.
/// Other effects (after effects) are applied on top of existing
/// SynthesizerEvents after the chain is constructed.
export abstract class SynthEffect {

    /// name of the effect
    name : string;

    /// array of parameter values applied dynamically to the effect
    params = new Array<Array<number>>();

    /// delayed start time of the effect in beats (0 means now)
    start = 0;

    /// duration of the effect in beats. a negative value indicates that this
    /// effect is constant (no dynamic changes over time)
    beats = -1.0;

    /// absolute time when this effect can be disconnected and discarded
    free = -1;

    /// node that gets inserted into the effects chain
    abstract get node() : AudioNode;

    /// original list of params generated by the python code
    oparams : EffectParams;

    /// unique id for this effect
    static _EFFECT_ID = 0;
    id : number;


    protected constructor (name : string, oparams : EffectParams) {
        this.id = SynthEffect._EFFECT_ID++;
        this.name = name;
        this.oparams = oparams;
        this.start = Math.max(0, oparams.start);
        this.beats = oparams.beats;
        this.free = -1;
        for (const c of oparams.values) {
            const values = Array<number>();
            if (Array.isArray(c)) {
                for (const val of c) values.push(val);
            }
            else if (typeof c === 'number') {
                values.push(c);
            }
            this.params.push(values);
        }
    }

    static createEffect(t : TraceEvent, context : BaseAudioContext) : SynthEffect {
        return new EmptyEffect(context);
        /*
        switch (t['effect']) {
        case 'lowpass':
        case 'highpass':
        case 'bandpass':
        case 'notch':
            return BiquadFilter(t['effect'], t.params, context);
        case 'filter':
            return BiquadFilter('lowpass', t.params, context);
        case 'pan':
            return PanEffect(t.params, context);
        case 'gain':
            return GainEffect(t.params, context);
        case 'bend':
            return PitchBendEffect(t.params, context);
        case 'reverb':
            return ReverbEffect(t.params, context);
        default:
            return EmptyEffect(context);
        }
        */
    }



    /// connect this effect to the destination node. returns the source
    /// audio node for this effect.
    /// subclasses must override. by default this is just a bypass
    /// delta is in beats
    connect(dest : AudioNode, bpm : number, delta : number) : AudioNode {
        this.free = (delta + this.start + this.beats + 0.1) * (60 / bpm) + dest.context.currentTime;
        this.node.connect(dest);
        return this.node;
    }


    /// disconnect and dispose of the audio nodes used in this effect
    disconnect() {
        this.node.disconnect();
    }


    /// override to apply after effects to notes
    ///   gen: tone generator scheduled to play the note
    ///   noteStart: the start time of the note in beats
    ///   noteDuration: the duration of the note in beats
    ///   bpm: current tempo, used to convert beats to seconds
    ///   delta: time before the start of the next measure (in beats)
    ///      when this note is to be scheduled. if negative, it means
    ///      to skip the beginning of a loop
    afterEffect(gen : SynthChain | undefined, noteStart : number, noteDuration : number, bpm : number, delta : number) {
    }


    /// clamp all of the parameter values within a range
    clampParam(param : Array<number>, minVal : number, maxVal : number) {
        for (let i=0; i<param.length; i++) {
            param[i] = clamp(param[i], minVal, maxVal);
        }
    }
}


export class EmptyEffect extends SynthEffect {
    private _node : GainNode;

    get node() : AudioNode { return this._node; }

    constructor(context : BaseAudioContext) {
        super('empty', DefaultEffectParams);
        this._node = new GainNode(context);
    }
}

/*
/// Standard lowpass filter. Recognizes a frequency
/// parameter, a "Q"uality parameter, and a gain parameter
class BiquadFilter extends Effect {

  /// filter type (e.g. "lowpass", "highpass", "bandpass", "notch")
  String type = "lowpass";

  List<num> get frequency => this.params[0];

  List<num> get Q => this.params[1];

  List<num> get gain => this.params[2];


  BiquadFilter(String name, Map<String, dynamic> oparams, BaseAudioContext context) :
  super._internal(name, oparams) {

    this.node = BiquadFilterNode(context) .. type = name;
    this.type = name;

    if (this.params.isEmpty) {
      this.params.add(<num>[]);
      this.frequency.add(1000);
    }

    if (this.params.length < 2) {
      this.params.add(<num>[]);
      this.Q.add(3);
    }

    if (this.params.length < 3) {
      this.params.add(<num>[]);
      this.gain.add(1.0);
    }

    clampParam(frequency, 10, 22050);
    if (name == "highpass" || name == "lowpass") clampParam(Q, 0.0001, 30.0);
  }


  AudioNode connect(AudioNode dest, int bpm, num delta) {
    this.free = (delta + start + beats + 0.1) * (60 / bpm) + dest.context!.currentTime!;
    node.connectNode(dest);

    AudioParam fp = (node as BiquadFilterNode).frequency!;
    AudioParam qp = (node as BiquadFilterNode).Q!;
    AudioParam gp = (node as BiquadFilterNode).gain!;

    EffectCurve fcurve = EffectCurve(frequency, beats * (60 / bpm));
    EffectCurve qcurve = EffectCurve(Q, beats * (60 / bpm));
    EffectCurve gcurve = EffectCurve(gain, beats * (60 / bpm));

    fcurve.apply(fp, (delta + start) * (60 / bpm), dest.context!);
    qcurve.apply(qp, (delta + start) * (60 / bpm), dest.context!);
    gcurve.apply(gp, (delta + start) * (60 / bpm), dest.context!);

    return node;
  }
}


/// Pitch bend effect
class PitchBendEffect extends Effect {

  List<num> get values => this.params[0];

  PitchBendEffect(Map<String, dynamic> params, BaseAudioContext context)
  : super._internal('bend', params) {
    this.node = GainNode(context);
  }

  /// pitch bend is applied to notes after they have been scheduled to play
  ///   gen: tone generator scheduled to play the note
  ///   noteStart: the start time of the note in beats
  ///   noteDuration: the duration of the note in beats
  ///   bpm: current tempo, used to convert timing to seconds
  ///   delta: time before the start of the next measure (in beats)
  ///      when this note is to be scheduled. if negative, it means
  ///      to skip the beginning of a loop
  void afterEffect(SynthChain ? gen, num noteStart, num noteDuration, int bpm, num delta) {
    if (values.length == 1 && beats > 0) values.insert(0, 0.0);

    //---------------------------------------------
    // convert everything to seconds
    //---------------------------------------------
    noteStart = (noteStart + delta) * (60 / bpm);  // can be negative
    noteDuration *= (60 / bpm);
    num noteEnd = noteStart + noteDuration;
    num bendStart = (delta + start) * (60 / bpm);  // can be negative
    num bendDuration = beats * (60 / bpm);
    num bendEnd = bendStart + bendDuration;

    //---------------------------------------------
    // build effect curve and trim to fit note
    //---------------------------------------------
    EffectCurve curve = EffectCurve(values, bendDuration);
    if (noteStart > bendStart) curve.trimStart(noteStart - bendStart);
    if (noteEnd < bendEnd) curve.trimEnd(bendEnd - noteEnd);

    //---------------------------------------------
    // schedule the trimmed bend to happen
    //---------------------------------------------
    gen?.schedulePitchBend(max(noteStart, bendStart), curve);
  }
}


class PanEffect extends Effect {

  List<num> get values => this.params[0];


  PanEffect(Map<String, dynamic> params, BaseAudioContext context) : super._internal('pan', params) {
    this.node = StereoPannerNode(context);
    clampParam(values, -1.0, 1.0);
  }


  AudioNode connect(AudioNode dest, int bpm, num delta) {
    this.free = (delta + start + beats + 0.1) * (60 / bpm) + dest.context!.currentTime!;

    node.connectNode(dest);

    AudioParam p = (node as StereoPannerNode).pan!;
    EffectCurve curve = EffectCurve(values, beats * (60 / bpm));
    /// FIXME
    curve.apply(p, (delta + start) * (60 / bpm), dest.context!);
    return node;
  }
}


class GainEffect extends Effect {

  List<num> get values => this.params[0];

  GainEffect(Map<String, dynamic> params, BaseAudioContext context) : super._internal('gain', params) {
    this.node = GainNode(context);

  }


  AudioNode connect(AudioNode dest, int bpm, num delta) {
    this.free = (delta + start + beats + 0.1) * (60 / bpm) + dest.context!.currentTime!;

    node.connectNode(dest);

    AudioParam param = (node as GainNode).gain!;

    if (values.length == 1 || beats <= 0) {
      //num g = (id % 2 == 1) ? 0 : 0.25 * values[0];
      num g = values[0] * values[0];
      param.setValueAtTime(g, 0);
    } else {
      EffectCurve curve = EffectCurve(values, beats * (60 / bpm));
      // map values to gain
      for (int i=0; i<curve.curve.length; i++) {
        curve.curve[i] = (curve.curve[i] * curve.curve[i]);
      }
      curve.apply(param, (delta + start) * (60 / bpm), dest.context!);
    }

    return node;
  }
}



class ReverbEffect extends Effect {

  //String impulseName;

  final String impulseURL = '/assets/sounds/impulses/bright-hall.wav';

  /// wet-dry level
  List<num> get values => this.params[1];

  /// control the wet v dry level
  late GainNode wet;
  late GainNode dry;

  /// convolution node
  late ConvolverNode convolve;

  /// TODO: re-enable these as sounds built into the repo

  Map<String, int> impulseResponseMap = {
    // UI Name -> Sound recording number
    "hall": 133,
    "gallery": 134,
    "museum": 135,
    "library": 200,
    "theatre": 199,
    "underpass": 198,
    "spaceecho2": 188,
    "vintagespring": 189,
    "plateshortpcm60": 195,
    "platemediumpcm60": 194,
    "platelongpcm60": 193,
    "roomshortpcm60": 192,
    "roommediumpcm60": 191,
    "roomlongpcm60": 190,
    "voxac30regular": 196,
    "voxac30bright": 197,
  };



  ReverbEffect(Map<String, dynamic> params, BaseAudioContext context) :
  super._internal('reverb', params) {
    node = GainNode(context);
    //wet = GainNode(context);
    //dry = GainNode(context);
    //convolve = ConvolverNode(context);

    //node.connectNode(dry);
    //node.connectNode(convolve);
    //convolve.connectNode(wet);

    // impulseName = params['values'][0];
    clampParam(values, 0.0, 1.0);
  }


  AudioNode connect(AudioNode dest, int bpm, num delta) {
    this.free = (delta + start + beats + 0.1) * (60 / bpm) + dest.context!.currentTime!;
    node.connectNode(dest);

    //_connect(dest, bpm, delta); // call async version of the function
    return node;
  }

  /// disconnect and dispose of the audio nodes used in this effect
  void disconnect() {
    node.disconnect();
    //wet.disconnect();
    //dry.disconnect();
    //convolve.disconnect();
  }
*/

/*
  Future _connect(AudioNode dest, int bpm, num delta) async {
    await Synthesizer.loadCustomSound(impulseURL, dest.context!);
    convolve.buffer = Synthesizer.getAudioBuffer(impulseURL);

    if (values.length == 1 || beats <= 0) {
      num gain = values[0] * values[0];
      wet.gain?.setValueAtTime(gain, 0);
      dry.gain?.setValueAtTime(1 - gain, 0);
    }
    else {
      EffectCurve curve = EffectCurve(values, beats * (60 / bpm));
      // map values to gain for wet and dry
      EffectCurve wetCurve = curve.map((t) => t * t);
      EffectCurve dryCurve = curve.map((t) => 1 - (t * t));

      wetCurve.apply(wet.gain!, (delta + start) * (60 / bpm), dest.context!);
      dryCurve.apply(dry.gain!, (delta + start) * (60 / bpm), dest.context!);
    }

    wet.connectNode(dest);
    dry.connectNode(dest);
  }
  */
//}
